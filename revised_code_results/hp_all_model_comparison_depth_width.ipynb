{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7db291f8-ba21-4a83-b3b9-c441c0f3754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    BaggingRegressor,\n",
    "    ExtraTreesRegressor,\n",
    ")\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#df = pd.read_csv('D:\\PhD_ResearchWork\\ASME_Journal\\datasets\\Final\\LPBF_Dataset_polyExp(12features)Normalized.csv')\n",
    "\n",
    "#output='depth'\n",
    "#input_file='DataAug/LPBF_Final_Dataset/LPBF_Dataset_Normalized_Depth.csv'\n",
    "\n",
    "output='width'\n",
    "input_file='DataAug/LPBF_Final_Dataset/LPBF_Dataset_Normalized_Width.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "X=df.iloc[:, :-1]\n",
    "y=df.iloc[:, -1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree=2,include_bias=False), LinearRegression())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#('Polynomial Regression', poly_reg_model.fit(poly_features, y)),\n",
    "\n",
    "ensemble_methods = [\n",
    "    ('Gaussian Process', GaussianProcessRegressor(kernel=DotProduct() + WhiteKernel(), random_state=42)),\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Polynomial Regression',poly_model),\n",
    "    ('Support Vector Regression', SVR(kernel='linear', C=.5)),\n",
    "    ('KNN', KNeighborsRegressor(n_neighbors=2)),\n",
    "    ('Multi Layer Perception',\n",
    "     MLPRegressor(activation='relu', hidden_layer_sizes=(10, 100), alpha=0.001, random_state=42, early_stopping=False)),\n",
    "    ('Random Forest', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, random_state=42)),\n",
    "    ('AdaBoost', AdaBoostRegressor(n_estimators=100, random_state=42)),\n",
    "    ('Bagging', BaggingRegressor(n_estimators=100, random_state=42)),\n",
    "    ('Extra Trees', ExtraTreesRegressor(n_estimators=100, random_state=42)),\n",
    "]\n",
    "\n",
    "k = 10\n",
    "\n",
    "\n",
    "results_list = []\n",
    "\n",
    "\n",
    "for name, model in ensemble_methods:\n",
    "\n",
    "    row = {'Model': name}\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    \n",
    "    # Use cross_val_score to get mean squared error and mean absolute error\n",
    "    mse_scores = -cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "    mae_scores = -cross_val_score(model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "    r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mse_scores.mean()\n",
    "    mae = mae_scores.mean()\n",
    "    corr = r2_scores.mean()\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    rmse = np.sqrt(mse)\n",
    "    rae = mae / np.mean(np.abs(y - np.mean(y)))\n",
    "    rrse = rmse / np.sqrt(np.mean((y - np.mean(y))**2))\n",
    "\n",
    "    results_list.append({\n",
    "        'Model': name,\n",
    "        'R-squared': corr,\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'RAE': rae,\n",
    "        'RRSE': rrse\n",
    "    })\n",
    "\n",
    "   \n",
    "\n",
    "results = pd.DataFrame(results_list)\n",
    "# Save results to a CSV file\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "filename = f'{output}_hp_model_comparison_results_{timestamp}.csv'\n",
    "\n",
    "results.to_csv(filename, index=False)\n",
    "\n",
    "#opt.to_csv('All_ML_models_Results_v3_Poly_Width(12features).csv',mode='w', index=False)\n",
    "\n",
    "#opt.to_csv('All_ML_models_Results_depth.csv',mode='w', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0170d81-5753-4e99-b29a-e95075ef0ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OLCF-CUDA11 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
